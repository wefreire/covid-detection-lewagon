{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6717213,"sourceType":"datasetVersion","datasetId":1317048}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#===========================================================================================================================\n#========================================BLOCK 1: CONFIGURATION & IMPORTS===================================================\n#===========================================================================================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# --- CONFIGURATION ---\nclass Config:\n    SEED = 42  # Ensuring that everyone get the exact same split!\n    BATCH_SIZE = 32\n    EPOCHS = 15\n    IMAGE_SIZE = (224, 224)\n    LR = 1e-3  # Standard learning rate for frozen models\n    \n    # Kaggle Paths\n    BASE_PATH = '/kaggle/input/covidx-cxr2/'\n    \n    # Text Files\n    TRAIN_TXT = os.path.join(BASE_PATH, 'train.txt')\n    VAL_TXT   = os.path.join(BASE_PATH, 'val.txt')\n    TEST_TXT  = os.path.join(BASE_PATH, 'test.txt')\n    \n    # Image Folders\n    TRAIN_DIR = os.path.join(BASE_PATH, 'train')\n    VAL_DIR   = os.path.join(BASE_PATH, 'val')\n    TEST_DIR  = os.path.join(BASE_PATH, 'test')\n\n# Set Seed for Reproducibility\nnp.random.seed(Config.SEED)\ntf.random.set_seed(Config.SEED)\nprint(\"Configuration set. Seed fixed to:\", Config.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T19:06:08.249629Z","iopub.execute_input":"2025-11-28T19:06:08.250189Z","iopub.status.idle":"2025-11-28T19:06:27.660908Z","shell.execute_reply.started":"2025-11-28T19:06:08.250161Z","shell.execute_reply":"2025-11-28T19:06:27.660048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#========================================BLOCK 2: REORGANIZE DATASET========================================================\n#===========================================================================================================================\n\n# --- 1. HELPER FUNCTION TO LOAD DATA ---\ndef read_data(txt_path, image_folder):\n    \"\"\"Reads a text file and adds the full path to the image folder.\"\"\"\n    # Read the file (Space separated)\n    df = pd.read_csv(txt_path, sep=' ', header=None)\n    df.columns = ['patient_id', 'filename', 'label', 'source']\n    \n    # Create the full path column so the generator can find the image later\n    df['path'] = df['filename'].apply(lambda x: os.path.join(image_folder, x))\n    return df\n\n# --- 2. LOAD EVERYTHING ---\nprint(\"Loading original datasets...\")\ndf_train = read_data(Config.TRAIN_TXT, Config.TRAIN_DIR)\ndf_val   = read_data(Config.VAL_TXT,   Config.VAL_DIR)\ndf_test  = read_data(Config.TEST_TXT,  Config.TEST_DIR)\n\n# Combine them all into one big list\nfull_df = pd.concat([df_train, df_val, df_test], axis=0).reset_index(drop=True)\nprint(f\"Total images found: {len(full_df)}\")\n\n# --- 3. BALANCE THE DATA ---\n# Balancing data BEFORE splitting to keep things fair\nmin_count = full_df['label'].value_counts().min()\nprint(f\"Balancing dataset to {min_count} images per class...\")\n\n# Take a random sample of 'min_count' from each class\nbalanced_df = full_df.groupby('label').apply(\n    lambda x: x.sample(min_count, random_state=Config.SEED)\n).reset_index(drop=True)\n\n# Shuffle the final dataframe\nbalanced_df = balanced_df.sample(frac=1, random_state=Config.SEED).reset_index(drop=True)\n\n# --- 4. CREATE NEW SPLITS ---\n# Split 1: 80% for Training, 20% for Temp (Val + Test)\ntrain_df, temp_df = train_test_split(\n    balanced_df, \n    train_size=0.8, \n    stratify=balanced_df['label'], # Ensures 50/50 split in train\n    random_state=Config.SEED\n)\n\n# Split 2: Split the Temp (20%) into half for Val and half for Test\nval_df, test_df = train_test_split(\n    temp_df, \n    train_size=0.5, \n    stratify=temp_df['label'], \n    random_state=Config.SEED\n)\n\nprint(f\"New Train Size: {len(train_df)}\")\nprint(f\"New Val Size:   {len(val_df)}\")\nprint(f\"New Test Size:  {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T19:06:27.662272Z","iopub.execute_input":"2025-11-28T19:06:27.662760Z","iopub.status.idle":"2025-11-28T19:06:28.124990Z","shell.execute_reply.started":"2025-11-28T19:06:27.662739Z","shell.execute_reply":"2025-11-28T19:06:28.124134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#=============================================BLOCK 3: GENERATORS===========================================================\n#===========================================================================================================================\n\n# --- PREPROCESSING ---\n# Using the official DenseNet preprocessing function\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=20,       # Rotate slightly\n    horizontal_flip=True,    # Flip left/right\n    fill_mode='nearest'\n)\n\n# Test/Val data should NOT be augmented, only preprocessed\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n# --- FLOWS ---\nprint(\"Creating Data Generators...\")\n\ntrain_gen = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='path',\n    y_col='label',\n    target_size=Config.IMAGE_SIZE,\n    batch_size=Config.BATCH_SIZE,\n    class_mode='binary',\n    shuffle=True,\n    seed=Config.SEED\n)\n\nval_gen = test_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col='path',\n    y_col='label',\n    target_size=Config.IMAGE_SIZE,\n    batch_size=Config.BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)\n\ntest_gen = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='path',\n    y_col='label',\n    target_size=Config.IMAGE_SIZE,\n    batch_size=Config.BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T19:06:28.125917Z","iopub.execute_input":"2025-11-28T19:06:28.126181Z","iopub.status.idle":"2025-11-28T19:07:49.960727Z","shell.execute_reply.started":"2025-11-28T19:06:28.126150Z","shell.execute_reply":"2025-11-28T19:07:49.959983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#=============================================BLOCK 4: SEQUENTIAL MODEL=====================================================\n#===========================================================================================================================\n\n# --- BUILD MODEL ---\n# 1. Download the Base Model (DenseNet121)\nbase_model = DenseNet121(\n    include_top=False,    # Remove the original \"1000 classes\" head\n    weights='imagenet',   # Use pre-trained knowledge\n    input_shape=(224, 224, 3)\n)\n\n# 2. Freeze the Base Model\nbase_model.trainable = False \n\n# 3. Build the Sequential Stack\nmodel = Sequential([\n    base_model,                                 \n    GlobalAveragePooling2D(),                   \n    Dense(128, activation='relu'),              \n    BatchNormalization(),                       \n    Dropout(0.2),                               \n    Dense(1, activation='sigmoid')\n])\n\n# 4. Compile\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=Config.LR),\n    loss='binary_crossentropy', # Matches Sigmoid\n    metrics=['accuracy']\n)\n\nprint(\"Model built successfully!\")\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T19:07:49.962237Z","iopub.execute_input":"2025-11-28T19:07:49.962505Z","iopub.status.idle":"2025-11-28T19:07:55.029126Z","shell.execute_reply.started":"2025-11-28T19:07:49.962483Z","shell.execute_reply":"2025-11-28T19:07:55.028556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#=================================================BLOCK 5: TRAINING=========================================================\n#===========================================================================================================================\n\n# --- CALLBACKS ---\ncallbacks = [\n    # Stop if validation loss doesn't improve for 5 epochs\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n    \n    # Save the best version of the model\n    ModelCheckpoint('best_covid_model.keras', monitor='val_loss', save_best_only=True, verbose=1),\n    \n    # Slow down learning rate if we get stuck\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n]\n\n# --- TRAIN ---\nprint(\"Starting training...\")\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=Config.EPOCHS,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T19:07:55.029857Z","iopub.execute_input":"2025-11-28T19:07:55.030097Z","iopub.status.idle":"2025-11-28T20:30:55.165671Z","shell.execute_reply.started":"2025-11-28T19:07:55.030059Z","shell.execute_reply":"2025-11-28T20:30:55.165132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#=================================================BLOCK 6: EVALUATION=======================================================\n#===========================================================================================================================\n\n# --- EVALUATION ---\nprint(\"\\n--- Final Evaluation on Test Set ---\")\n\n# 1. Load the best weights\nmodel.load_weights('best_covid_model.keras')\n\n# 2. Predict\npredictions = model.predict(test_gen)\n\n# 3. Convert probabilities to classes (Threshold 0.5)\ny_pred = (predictions > 0.5).astype(int)\ny_true = test_gen.classes\n\n# 4. Show Results\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Negative', 'Positive'], \n            yticklabels=['Negative', 'Positive'])\nplt.title('Confusion Matrix (Merged Dataset)')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\nprint(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T20:30:55.167054Z","iopub.execute_input":"2025-11-28T20:30:55.167525Z","iopub.status.idle":"2025-11-28T20:32:44.563211Z","shell.execute_reply.started":"2025-11-28T20:30:55.167483Z","shell.execute_reply":"2025-11-28T20:32:44.562521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#===========================================================================================================================\n#=================================================BLOCK 7: SAVE FINAL MODEL=================================================\n#===========================================================================================================================\n\n# --- SAVE MODEL ---\n# 1. Save the final state of the model\nsave_path = 'my_final_covid_model.keras'\nprint(f\"Saving final model to {save_path}...\")\nmodel.save(save_path)\n\nprint(\"Model saved successfully!\")\n\n# Note for Teammates:\n# To load this model later, they just need to run:\n# new_model = tf.keras.models.load_model('my_final_covid_model.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T20:32:44.564012Z","iopub.execute_input":"2025-11-28T20:32:44.564396Z","iopub.status.idle":"2025-11-28T20:32:45.984738Z","shell.execute_reply.started":"2025-11-28T20:32:44.564363Z","shell.execute_reply":"2025-11-28T20:32:45.984038Z"}},"outputs":[],"execution_count":null}]}